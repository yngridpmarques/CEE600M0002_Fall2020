{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Hyperspectral Data with Principal Components Analysis (PCA) in Python\n",
    "## Adapted from here: https://www.neonscience.org/classification-pca-python\n",
    "### AUTHORS: Paul Gader\n",
    "In this tutorual, we'll reduce the number of features in a hyperspectral image using the Principal Components Analysis (PCA) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "from scipy import io\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we'll look at how to define a function in Python:\n",
    "There are several components needed to define a function in Python, including the def keyword, function name, parameters (inputs), and the return statement, which specifies the output of the function.\n",
    "\n",
    "    def function_name(parameter):\n",
    "        some code here    \n",
    "        return output\n",
    "        \n",
    "To apply \"some code here\" to parameter MyParam, you just type:\n",
    "\n",
    "    function_name(parameter = MyParam)\n",
    "    \n",
    "*Learn more about functions in Python here: https://www.earthdatascience.org/courses/intro-to-earth-data-science/write-efficient-python-code/functions-modular-code/write-functions-in-python/*\n",
    "\n",
    "This function lets us plot the spectral signature of an image, with mean reflectance plotted in red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotSpectraAndMean(Spectra, Wv, fignum):\n",
    "    #The function \"PlotSpectraAndMean\" plots the spectrum of a multivariate image. It takes 3 parameters as inputs:\n",
    "    # Spectra: vector of reflectance values for each band (as concantonated rows). Spectra is NBands x NSamps\n",
    "    # Wv: wavelengths of NBands\n",
    "    # fignum: plt.figure formatting parameter\n",
    "    \n",
    "    ### Spectra is NBands x NSamps\n",
    "    mu = np.mean(Spectra, axis=1) #calculates the mean value of spectra\n",
    "    print(np.shape(mu)) #prints out shape of mu, mean reflectance across bands, should be vector of lengt NSamp\n",
    "    plt.figure(fignum) #sets plt.figure parameter\n",
    "    plt.plot(Wv, Spectra, 'c') # plots \"Spectra\" in cyan ('c')\n",
    "    plt.plot(Wv, mu, 'r') # plots \"mu\" in red ('r')\n",
    "    plt.show() # print plot\n",
    "    return mu # print mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "In this tutorial, we're using a very small hyperspectral image downloaded from the NEON dataset:\n",
    "\n",
    "https://data.neonscience.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename   = './RSDI2017DataSpecClass/OSBSTinyIm.mat'\n",
    "ImDict     = io.loadmat(filename)\n",
    "OSBSTinyIm = ImDict['OSBSTinyIm']\n",
    "TinySize   = np.shape(OSBSTinyIm)\n",
    "NRows      = TinySize[0]\n",
    "NCols      = TinySize[1]\n",
    "NBands     = TinySize[2]\n",
    "print('{0:4d} {1:4d} {2:4d}'.format(NRows, NCols, NBands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: How many bands are in (OSBSTinyIm)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to know the specific wavelengths for the spectra bands in OSBSTinyIm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD WAVELENGTHS WITH WATER BANDS ###\n",
    "Wv = io.loadmat(\"./RSDI2017DataSpecClass/NEONWvsNBB\")\n",
    "Wv = Wv['NEONWvsNBB']\n",
    "print(np.shape(Wv))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(range(346), Wv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Add a descriptive title, y axis label, and x axis label to this plot (hint: plt.ylabel()... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HAVE TO SUBTRACT AN OFFSET BECAUSE OF BAD BAND REMOVAL AND 0-BASED Python vs 1-Based MATLAB   ###\n",
    "Offset     = 7\n",
    "\n",
    "### LOAD & PRINT THE INDICES FOR THE COLORS   ###\n",
    "### AND DIG THEM OUT OF MANY LAYERS OF ARRAYS ###\n",
    "NEONColors = io.loadmat('./RSDI2017DataSpecClass/NEONColors.mat')\n",
    "#This is a MAT-file, generated in matlab. Learn more about it before we move on:\n",
    "print(NEONColors)\n",
    "\n",
    "\n",
    "NEONRed    = NEONColors['NEONRed']\n",
    "NEONGreen  = NEONColors['NEONGreen']\n",
    "NEONBlue   = NEONColors['NEONBlue']\n",
    "NEONNir    = NEONColors['NEONNir']\n",
    "NEONRed    = NEONRed[0][0]-Offset\n",
    "NEONGreen  = NEONGreen[0][0]-Offset\n",
    "NEONBlue   = NEONBlue[0][0]-Offset\n",
    "NEONNir    = NEONNir[0][0]-Offset\n",
    "print('Indices:     {0:4d} {1:4d} {2:4d} {3:4d}'.format(NEONRed, NEONGreen, NEONBlue, NEONNir))\n",
    "\n",
    "### CONVERT THE INDICES TO WAVELENGTHS ###\n",
    "NEONRedWv    = Wv[NEONRed][0]\n",
    "NEONGreenWv  = Wv[NEONGreen][0]\n",
    "NEONBlueWv   = Wv[NEONBlue][0]\n",
    "NEONNirWv    = Wv[NEONNir][0]\n",
    "print('Wavelengths: {0:4d} {1:4d} {2:4d} {3:4d}'.format(NEONRedWv, NEONGreenWv, NEONBlueWv, NEONNirWv))\n",
    "\n",
    "print(\"When read into Python, the MAT-file is turned into a: \") \n",
    "type(NEONColors['NEONRed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the RGB bands specified in NEONColors index file, we'll plot a RBG composite representation of OSBSTinyIm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGBIm = OSBSTinyIm[:, :, [NEONRed, NEONGreen, NEONBlue]]\n",
    "RGBIm = np.sqrt(RGBIm) \n",
    "plt.figure(2)\n",
    "plt.imshow(RGBIm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: What does np.sqrt do to this image? \n",
    "## How many dimensions were in RBGIm before np.sqrt? \n",
    "## How many dimensions were in RBGIm after np.sqrt? \n",
    "## What does plt.imshow do? \n",
    "## What happens if we don't use np.sqrt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to think about a raster dataset is that every individual pixel, or cell, is an object. Just like with our vector spatial data, each spatial object has a row of value(s) associated with it in the attribute table, viewing each pixel as a distinct spatial object (record) us to create a similar dataframe, where rows represent unique pixels and columns represent multivariate observations at that pixel location. \n",
    "\n",
    "In order to rearrange the raster back from the dataframe, we'll need to keep careful check of where our rows and columns have lined up.\n",
    "\n",
    "Since we read a Matlab object into Python, there will be a few translational differences that need to be taken into account. Above, we saw that on issue arrises with different indexing values (the first item in a series is \"0\" in Python, \"1\" in Matlab). There are also differences in how an array is concantonated into a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HAVE TO TAKE INTO ACCOUNT DIFFERENCES BETWEEN Python AND Matlab ###\n",
    "### Python USES THE    C     PROGRAMMING LANGUAGE ORDERING ###\n",
    "### MATLAB USERS THE FORTRAN PROGRAMMING LANGUAGE ORDERING ###\n",
    "### Python WOULD RESHAPE BY REFERENCE AND MATLAB BY VALUE  ###\n",
    "### THEREFORE, WE NEED TO COPY THE VALUES EXPLICITLY       ###\n",
    "TinyVecs = OSBSTinyIm.reshape(NRows*NCols, NBands, order='F').copy()\n",
    "\n",
    "### MATLAB TREATS THE ROWS AS DATA SAMPLES ###\n",
    "### np  TREATS THE COLS AS DATA SAMPLES ###\n",
    "TinyVecs = np.transpose(TinyVecs)\n",
    "NSamps   = np.shape(TinyVecs)[1]\n",
    "np.shape(TinyVecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But representing our data in this way allows us to plot the image's spectral signature, like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the function \"PlotSpectraAndMean\", defined above.\n",
    "SpecIndices = range(1000, 2000, 100)\n",
    "SomeSpectra = TinyVecs[:, range(1000, 2000, 100)]\n",
    "mymu        = PlotSpectraAndMean(SomeSpectra, Wv, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(mymu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4: Edit the plot to label the y and x axis, using code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Indices of Spectra to Try ###\n",
    "### SpecIndices = range(0, 1000, 100) ###\n",
    "SpecIndices = range(1000, 2000, 100)\n",
    "SomeSpectra = TinyVecs[:, range(1000, 2000, 100)]\n",
    "plt.figure(3)\n",
    "plt.plot(Wv, SomeSpectra)\n",
    "plt.xlabel('Enter label here')\n",
    "plt.ylabel('Enter label here')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the data, we can see instances where the average reflectance of nearby (on the electromagnetic spectrum) bands tend to be similar to each other. This represents a form of collinearity in our data: it's an instance where we lack good cross-replication.\n",
    "\n",
    "We can approximate the degree of collinearity between spectral bands by quantifying its ***covariance matrix:***\n",
    "\n",
    "In the ***covariance matrix***, we calculate pairwise the joint probability of two random variables (in units of reflectance squared). Higher values indicate more covariance.\n",
    "\n",
    "On diagonal, we're essentially measuring the covariance of a variable with itself, which is equal to the variable's variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(TinyVecs))\n",
    "C = np.cov(TinyVecs)\n",
    "print(np.shape(C))\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(6)\n",
    "plt.imshow(C)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "OK, let's do PCA\n",
    "\n",
    "First, we'll calculate TinyVecsZ as the mean-subtracted version of the original spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(TinyVecs, axis=1)\n",
    "TinyVecsZ = np.zeros((NBands, NSamps))\n",
    "for n in range(NSamps):\n",
    "    TinyVecsZ[range(NBands),n]= TinyVecs[(range(NBands), n)]-mu\n",
    "\n",
    "muz = np.mean(TinyVecsZ, axis=1)\n",
    "plt.figure(5)\n",
    "plt.plot(Wv, muz, 'k')\n",
    "#plt.ylim(-1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll calculate the covariance matrix on the norm of TinyVecs. Then, we'll computee the eigenvalues (D) and right eigenvectors (V) of the covariance matrix using the linalg.eig() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C   = np.cov(TinyVecsZ)\n",
    "D,V = linalg.eig(C)\n",
    "D   = D.real\n",
    "print(np.shape(D))\n",
    "print(np.shape(V))\n",
    "print(TinyVecsZ.shape)\n",
    "print(V[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But what do these mean?\n",
    "How do we interpret D and V in terms of our data?\n",
    "\n",
    "The eigenvectors (V) and eigenvalues (D) of a covariance matrix represent the “core” of a PCA: The eigenvectors (principal components) determine the directions of the new feature space, and the eigenvalues determine their magnitude.\n",
    "\n",
    "Plotting our eigenvalues gives us an idea how much variance in our total data is encoded in each eigenvector:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(10)\n",
    "print(D.shape)\n",
    "DiagD = np.diag(D)\n",
    "print(D.shape)\n",
    "plt.plot(DiagD)\n",
    "#Exercise\n",
    "#plt.plot(D[range(10)])\n",
    "#plt.plot(D[range(10, 30, 10)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5: In the cell above, try cancelling and uncancelling the different plt.plot() arguments. Based on the eigvenvalues, how many eigenvectors do we need to explain the vast majority of variance in our data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projecting our data into Principal Component Space\n",
    "By taking the dot product (np.dot) of the transpose of our eigenvectors (V.T) and our original data, we can project our data into the principal component pace TinyVecsPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TinyVecsPCA = np.dot(V.T, TinyVecsZ) \n",
    "PCACovar    = np.cov(TinyVecsPCA)\n",
    "D,V         = linalg.eig(C)\n",
    "D           = D.real\n",
    "print(D.shape)\n",
    "print(PCACovar.shape)\n",
    "for r in range(10):\n",
    "    print('{0:5f} {1:5f}'.format(D[r], PCACovar[r,r]))\n",
    "print()\n",
    "for r in range(10):\n",
    "    for c in range(10):\n",
    "        NextVal = int(10000*PCACovar[r,c])\n",
    "        print('{0:5d}'.format(NextVal), end=\" \")\n",
    "    print('\\n')\n",
    "# #Delta       = np.sum(np.sum((PCACovar-D), axis=0), axis=0)\n",
    "# print(Delta)\n",
    "# plt.figure(11)\n",
    "# plt.plot(np.diag(PCACovar))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the values on the diagonal are the variances of each coordinate in the PCA transformed data. They drop off rapidly which is why one can reduce dimensionality by discarding components that have low variance. Also, notice that the diagonal matrix D produce by diagonalizing the covariance of x is the covariance of y = PCA(x).\n",
    "\n",
    "If the data are Gaussian, then the coordinates of y are uncorrelated and independent. If not, then only uncorrelated.\n",
    "\n",
    "Let's pull out the first 3 dimensions and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#note this % notation is an iPython magic command! It lets you act like you're running a terminal: more here https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "fig = plt.figure(13)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(TinyVecsPCA[0,range(NSamps)],TinyVecsPCA[1,range(NSamps)],TinyVecsPCA[2,range(NSamps)], marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coord in range(3):\n",
    "    P1 = TinyVecsPCA[coord, :]\n",
    "    PCAIm      = np.reshape(P1, (NRows, NCols), order='F')\n",
    "    plt.figure(14+coord)\n",
    "    plt.imshow(np.abs(PCAIm))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At the end of the day projecting your data into Principal Component space gives you a *reduced number* of features that are *uncorrelated*, but explain the *majority of variance in the data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6: Why is this important for inference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 7: What is another way you can reduce the number of features (hint, use your scientific know-how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you've completed this assignment, upload it onto Blackboard>coursework>Week 8 > PCA Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:class_env] *",
   "language": "python",
   "name": "conda-env-class_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
